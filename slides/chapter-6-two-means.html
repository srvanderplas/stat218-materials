<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Ch. 6: Comparing Two Means</title>
    <meta charset="utf-8" />
    <meta name="author" content="" />
    <link rel="stylesheet" href="css/default.css" type="text/css" />
    <link rel="stylesheet" href="css/default-fonts.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Ch. 6: Comparing Two Means

---




# Navigation


.large[By Section]
- 6.1: [start](#3) - [end](#15)
- 6.2: [start](#16) - [end](#36)
- 6.3: [start](#37) - [end](#49)

???

In Chapter 3, we learned how to handle quantitative data, tests, and intervals for a single mean. In Chapter 5, we started talking about what to do when there are 2 variables, but we were working with proportions. So, in Chapter 6, the next logical thing is to talk about what to do with 2 variables, where one of them is categorical and the other is quantitative. 

---
class:inverse,middle,center
# 6.1: Comparing Two Groups
## Quantitative Response

???

And just as in Chapter 5, where we first talked about how to display data with 2 variables using a segmented bar chart, we're going to spend section 6.1 on how to describe and visualize data where one of the variables is categorical and the other is quantitative. 

---
## Describing Distributions of Quantitative Data

- **5-number summary** - the minimum, lower quartile, median, upper quartile, and maximum of a set of data

  - **lower quartile** - 25% of the data lie below this value
  
  - **median** - 50% of the data lie below this value
  
  - **upper quartile** - 75% of the data lie below this value
  
&lt;img src="chapter-6-two-means_files/figure-html/unnamed-chunk-1-1.png" width="80%" style="display: block; margin: auto;" /&gt;

???

One way we would describe a distribution of continuous data is to use what is called a 5-number summary. This is basically a set of numbers that describe the full spread of the data: the minimum (lowest observation), the lower quartile, the median (50% through the data), the upper quartile, and the maximum (highest observation).


---
## Describing Distributions of Quantitative Data

- **5-number summary** - the minimum, lower quartile, median, upper quartile, and maximum of a set of data

  - **lower quartile** - 25% of the data lie below this value
  
  - **median** - 50% of the data lie below this value
  
  - **upper quartile** - 75% of the data lie below this value
  
&lt;img src="chapter-6-two-means_files/figure-html/unnamed-chunk-2-1.png" width="80%" style="display: block; margin: auto;" /&gt;

???


The quartiles are a bit unfamiliar, though. 

With the median, we look for the point such that 50% of the data is below and 50% is above. You can think of the lower quartile as the median of the bottom half of the data: It is the point such that 25% of the data is below and 75% of the data is above.

Similarly, the upper quartile is the point where 75% of the data is below and 25% of the data is above. 

If you have `\(n\)` observations, you can count `\(n/4\)` from the bottom, `\(n/2\)` , and `\(3n/4\)` to get the lower quartile, median, and upper quartile (roughly). If you have a fractional value, average the two observations you're between.


---
## Describing Distributions of Quantitative Data


&lt;img src="chapter-6-two-means_files/figure-html/unnamed-chunk-3-1.png" width="80%" style="display: block; margin: auto;" /&gt;

The distance between the two quartiles is called the **inter-quartile range**(IQR). The IQR is another measure of variability, along with the standard deviation.

The IQR is resistant (or *robust*) to extreme values and skewness, unlike the standard deviation.

???

The distance between the 25th and 75th percentiles (or the lower and upper quartiles) gives a rough measure of the spread of the distribution, without being affected by outliers. So for a skewed distribution, the standard deviation will be really affected by an extreme outlier, but the IQR won't change at all. 

---
## Describing Distributions of Quantitative Data

A **boxplot** (or box-and-whisker plot) is a visual display of the 5-number summary. 
- The box displays the middle 50% of the distribution and its width (the IQR) shows the spread of the bulk of the distribution. 
- The 'whiskers' extend to the 
    - smallest and largest values in the dataset 
    - OR the values in the dataset that are within 1.5\*IQR away from the edges of the box. 
        - Observations outside of the 1.5\*IQR range may be shown as dots and are outliers



???

A boxplot is one way to summarize a full distribution visually, using the 5-number summary. It's easy to draw/sketch, and doesn't require as much tediousness as drawing a histogram or dotplot by hand. 

There are a couple of variations, but in both, the "box" covers the middle 50% of the data, with a line through the box for the median.

Extending out from the box are the "whiskers". You can make boxplots with whiskers that extend to the lowest and highest values - a direct representation of the 5 number summary. But often, a more useful representation is to make the whiskers extend to the lowest observation or 1.5 * IQR from the edges of the box. This allows us to visually highlight the outliers, which are shown as dots if they fall outside of the 1.5IQR range outside of the box.




---
## Describing Distributions of Quantitative Data

&lt;img src="chapter-6-two-means_files/figure-html/unnamed-chunk-5-1.png" width="80%" style="display: block; margin: auto;" /&gt;

What are the following values?
- bottom whisker:
- lower quartile:
- median:
- upper quartile:
- top whisker:

Are there any outliers?


???

Let's make a boxplot for our data here. First, we'll do the easy stuff - the quartiles and median.

---
## Describing Distributions of Quantitative Data

&lt;img src="chapter-6-two-means_files/figure-html/unnamed-chunk-6-1.png" width="80%" style="display: block; margin: auto;" /&gt;

What are the following values?
- bottom whisker: 
- lower quartile: .red[7]
- median: .red[9]
- upper quartile: .red[12]
- top whisker:

Are there any outliers?

???


Then, we'll calculate the IQR: 12 - 7 = 5. 

1.5 * IQR is 7.5

---
## Describing Distributions of Quantitative Data

&lt;img src="chapter-6-two-means_files/figure-html/unnamed-chunk-7-1.png" width="80%" style="display: block; margin: auto;" /&gt;

- bottom whisker: .red[1.5 x IQR below lower quartile, or smallest observation]    
.red[7 - 1.5(12-7) = -0.5] or .red[3]    
.red[bottom whisker: 3]
- top whisker: .red[1.5 x IQR above upper quartile, or largest observation]    
.red[12 + 1.5(12-7) = 19.5] or .red[21]    
.red[top whisker: 19.5]

Are there any outliers?

???


Subtract the IQR from the lower quartile

Add it to the upper quartile

Take the least extreme value that exists in the data. 

---
## Describing Distributions of Quantitative Data

&lt;img src="chapter-6-two-means_files/figure-html/unnamed-chunk-8-1.png" width="80%" style="display: block; margin: auto;" /&gt;

What are the following values?
- bottom whisker: .red[3]
- lower quartile: .red[7]
- median: .red[9]
- upper quartile: .red[12]
- top whisker: .red[19.5] 

Are there any outliers? .red[Yes, at 21]

???

The top whisker extends from 12 to 19.5, but there is a single point beyond that --- that point is an outlier. Outliers are extreme points that sometimes represent rare occurrences and sometimes indicate data recording errors and other data quality issues - it depends on the field, and how extreme the outlier is. 


---
## Describing Distributions of Quantitative Data

Boxplots make it easy to compare distributions of different groups.
&lt;img src="chapter-6-two-means_files/figure-html/unnamed-chunk-9-1.png" width="80%" style="display: block; margin: auto;" /&gt;

???

Using boxplots, we can compare distributions - for instance, we can say that there are usually fewer cases of measles than any other reportable illness in California, but there have been a couple of years where there were unusually large numbers of measles cases. 

We can see that the distribution of mumps cases is highly skewed - the median is very close to the lower quartile, and the lowest observation is not much lower than the quartile. So most years, we have 75 or so cases of mumps in California, but... in the other years, if we have more than 75 cases, we may have a lot more than 75 cases. That's what a skewed distribution looks like. 

---
## In-Class Practice: Jean Pocket Sizes

Using the graph paper on the next page, create boxplots for each of the dimensions in the chart below. 

&lt;img src="chapter-6-two-means_files/figure-html/unnamed-chunk-10-1.png" width="80%" style="display: block; margin: auto;" /&gt;

.bottom[Data source: https://pudding.cool/2018/08/pockets/]

???

I was pretty proud of this exercise... and then class got cancelled. So I'd appreciate it if you'd follow along and pretend that it's a cool example. 

Someone went through and measured the pocket sizes in jeans for men and women. They measured several dimensions, but we're going to work with the height and width. 

You have all of the data here; practice creating boxplots for each men's dimension and women's dimension. 

When you're done, take a look at the Example 6.1 video in Box, where I work through this problem. I had to record that one on my tablet, so it's a good enough excuse to give you a chance to try things out yourself.

---
## In-Class Practice: Jean Pocket Sizes

![graph paper](figure/graph_paper.png)

What do you conclude about the distributions of front pocket maximum dimensions when comparing Men's jeans to Women's jeans?

???



---
## Exploration 6.1: Haircut Prices

Work through Exploration 6.1A. Upload your answers; you must complete at least 1-13. 

If you complete 14-19, you may get extra credit.


---
class:middle,inverse,center
## 6.2: Comparing Two Means: Simulation Based Approach

???

Welcome to chapter 6.2, where we'll be talking about the simulation based approach to comparing two group means.

---
## 3S strategy

1. Statistic
2. Simulation
3. Strength of Evidence

***

Our hypotheses are going to concern `\(\mu_1\)` and `\(\mu_2\)`... specifically, the value of `\(\mu_1 - \mu_2\)`.

We are interested in the long run (e.g. data collected forever) value of the difference between the group means

`\(\begin{align}H_0&amp;: \mu_1 - \mu_2 = 0\\H_A&amp;: \mu_1 - \mu_2 \;\{\neq,&gt;,&lt; \} \;0\end{align}\)`

???

Let's start by reviewing our 3S strategy: First, we calculate a statistic, then we conduct a simulation, and finally, we evaluate the strength of our evidence.

In Chapter 6.2, we're working with `\(\mu_1\)` and `\(\mu_2\)`. As with Chapter 5, what we care about in Chapter 6 is the value of the true difference in group means (or the long-run distance). 

By default, we'll assume our group means are the same - that is, our null hypothesis is generally going to be that `\(\mu_1 = \mu_2\)`, or, equivalently, that `\(\mu_1 - \mu_2 = 0\)`. Our alternative hypothesis is going to be some variation on "the group means aren't the same" - either greater than, less than, or not equal to, depending on the problem.

---
## Simulation 

Group | Value | Simulated Group
----- | ----- | ---------------
1 | a | 1
1 | b | 2 
1 | c | 1
2 | d | 1
2 | e | 2 
2 | f | 2

Assign new group labels to existing values

Think about sorting labeled index cards into stacks for each group.

???

To simulate this, we'll take all of our values and assign them new group labels. If the groups are the same, then shuffling the labels will make no difference in our statistic's value, right?


---
## Simulation 

![Simulation setup - index cards](figure/two-groups-simulation-start.png)

???


Let's imagine that we have observations on two different colors of index cards. We compute the average value of each group, and then subtract them to get our sample statistic.

---
## Simulation 

![Simulation round 1 - index cards](figure/two-groups-simulation-1.png)

???

In a simulation, we'll shuffle the two sets of cards together and then deal them back out so that there are the right number of cards in each stack. The cards are still colored by their original group, but we've assigned new group labels - stack 1 and stack 2. We compute the mean of all the values in each stack, subtract those, and get a simulated statistic.


---
## Simulation 

![Simulation setup - index cards](figure/two-groups-simulation-2.png) 

???

Then we shuffle again, average each stack again, and get another simulated statistic.

---
## Simulation 

![Simulation setup - index cards](figure/two-groups-simulation-3.png)

At each simulation, we recalculate our statistic - e.g. `\(\overline x_1 - \overline x_2\)`

???

Each time we conduct a new trial, we're simulating an entire experiment - we're assigning groups to outcome values.

---
## Simulation

Null hypothesis: Mean .underline[.hidden[measurement]] is the same in both groups

One repetition: Rerandomizing groups for each .underline[.hidden[measurement]]

Statistic: Difference in two group means

???

To recap, our null hypothesis is that the mean is the same in both groups. One repetition consists of rerandomizing groups for each measurement, and we calculate the difference in the two simulated group means.


---
## Simulation

Null hypothesis: Mean .underline[.red[measurement]] is the same in both groups

One repetition: Rerandomizing groups for each .underline[.red[measurement]]

Statistic: Difference in two group means

---
## Example - Didgeridoo playing and sleep apnea

Scientists examined whether Didgeridoo lessons reduced the symptoms of sleep apnea as measured by the Epworth scale (0-24). Individuals were assessed for sleep apnea at the beginning and end of an 8-week period; the difference in scores was recorded. 14 individuals were randomly assigned to receive Didgeridoo lessons, while 11 did not receive any intervention.

&lt;img src="chapter-6-two-means_files/figure-html/unnamed-chunk-11-1.png" width="80%" style="display: block; margin: auto;" /&gt;

???

This is an example from the book, but who doesn't like to say didgeridoo?

Evidently, some scientist got a didgeridoo and started taking lessons, and found that his sleep apnea improved. He was intrigued, so he set up a study with 25 individuals, randomly assigning 14 to receive didgeridoo lessons while 11 presumably found other hobbies.

The difference in sleep apnea scores over the 8 week period was recorded for each individual. 

Our groups are treatment/control (lessons or not), our response variable is the difference in sleep apnea scores after 8 weeks.

---
## Example - Didgeridoo playing and sleep apnea

`$$\begin{align}H_0: \mu_D - \mu_C &amp;= 0\\H_A: \mu_D - \mu_C &amp;&gt;0\end{align}$$`

In words:
- `\(H_0\)`: The difference in the average change in Epworth Scale score between those who received Didgeridoo lessons and those that did not is 0

- `\(H_A\)`: Those who received Didgeridoo lessons will have a higher average change in Epworth Scale score than those who did not.

Because there is random assignment, if we conclude `\(H_A\)`, we can say the change is due to the Didgeridoo lessons.

???

Setting up our null hypothesis, we define mu D to be the didgeridoo group, and mu C to be the control group. We start out with the assumption that they're equal - there is no effect of didgeridoo lessons, and any group differences are due to random chance alone.

Our alternative hypothesis is that didgeridoo lessons do actually matter and result in a larger change in sleep apnea scores.


---
## Example - Didgeridoo playing and sleep apnea

&lt;img src="chapter-6-two-means_files/figure-html/unnamed-chunk-12.gif" width="80%" style="display: block; margin: auto;" /&gt;

During each simulation, the group labels are shuffled and the difference in the means is calculated. The resulting simulation statistic distribution is used to calculate the p-value.

???

This animation shows the accumulation of 100 simulations using this data. On the left, you can see the "assigned" groups - the different plots; the points are separated out by their original group membership as well using color. 

In the 100 simulation trials we see here, there were no trials that randomly showed a value as extreme as what we observed.

We can't say our p-value is 0 because we haven't run enough simulations, but we can say that p is less than 0.01. 

---
## Example - Didgeridoo playing and sleep apnea

&lt;img src="chapter-6-two-means_files/figure-html/unnamed-chunk-13-1.png" width="80%" style="display: block; margin: auto;" /&gt;

Interpretation: 

???

We'd interpret this in the same way that we interpreted any other p-value: With p&lt;0.01, we have very strong evidence against the null hypothesis that the two groups are equal. We reject the null and conclude that Didgeridoo lessons cause sleep apnea scores to decrease relative to a control group. There is evidence that didgeridoo lessons reduce symptoms of sleep apnea.

--

.red[
With p &lt; 0.01, we have very strong evidence against the null hypothesis that the two groups experienced equivalent reductions in Epworth Scale scores. Therefore, we reject `\(H_0\)` and conclude that it is more plausible that the group who received Didgeridoo lessons had a higher average reduction in Epworth Scale score than the control group. There is evidence that Didgeridoo lessons reduce the symptoms of sleep apnea.
]


---
## Exploration 6.2

Complete Exploration 6.2, questions 1 - 15. Upload your results to Canvas. 

You may work in groups if you wish, just put everyone's name on the assignment and only turn it in once.


---
class:center,middle,inverse
## 6.3: Comparing Two Means: Theory-Based Approach

???

In Chapter 6.2, we talked about how to simulate studies comparing two means; in Chapter 6.3 we'll talk about a theory-based approach. I'll start with an example, but be on the lookout - with any theory based approach, we need two things (generally speaking) - validity conditions, and a formula for the standard error.

---
## Example 6.3: Breastfeeding and Intelligence

An article published in the journal Pediatrics (1999) studied whether and how children who were breastfed during infancy differed from those who weren't breastfed on an intelligence test. The study involved 323 white children recruited at birth in 1980-1981 from four Western Michigan Hospitals. After some initial exploration, the researchers deemed the participants in the study were representative of the community in terms of social class, maternal education, age, marital status, and sex of infant.

- Is this an experiment or an observational study? .hidden[Investigators did not assign treatments (breastfeeding/not) to infants]

- Is this a random sample? .hidden[No - infants were not randomly selected - they were 'recruited']

- Is this a representative sample? .hidden[Possibly, based on initial exploration by the researchers. If the population of interest is white infants, then maybe.]

- Can we make causal conclusions (e.g. breastfeeding causes increased intelligence) .hidden[No, we can't make causal conclusions, because there was no random assignment of treatments to observational units]

???

There are many, many studies examining the long-term effects of breastfeeding and formula feeding on factors later in life: asthma rates, intelligence, gut bacteria levels, obesity rates.

In this study, researchers recruited mother-infant pairs from 4 western Michigan hospitals, and, one assumes due to the demographic limitations, this study involved only white infants born in 1980 or 1981. The researchers determined after collecting the data that certain demographic variables from their sample were representative of the community.

On your own, think through the following questions, before I give you the answers. If it helps, pretend I'm staring you down.

Is this an experiment or an observational study?

Did the researchers use a random sample?

Is their sample representative?

Can we draw any causal conclusions from the study?


---
## Example 6.3: Breastfeeding and Intelligence

An article published in the journal Pediatrics (1999) studied whether and how children who were breastfed during infancy differed from those who weren't breastfed on an intelligence test. The study involved 323 white children recruited at birth in 1980-1981 from four Western Michigan Hospitals. After some initial exploration, the researchers deemed the participants in the study were representative of the community in terms of social class, maternal education, age, marital status, and sex of infant.


- Is this ~~an experiment~~ or an observational study? .red[Investigators did not assign treatments (breastfeeding/not) to infants]

- Is this a random sample? .red[No - infants were not randomly selected - they were 'recruited']

- Is this a representative sample? .red[Possibly, based on initial exploration by the researchers. If the population of interest is white infants, then maybe.]

- Can we make causal conclusions (e.g. breastfeeding causes increased intelligence) .red[No, we can't make causal conclusions, because there was no random assignment of treatments to observational units]

???

This is an observational study, because investigators did not assign treatments (breastfeeding/formula feeding) to infants. It would be unethical to do so, and impractical as well, since not all mothers can breastfeed successfully, and not all infants tolerate formula due to allergies, reflux, and other issues. 
It's very hard to do experiments on infants... ethical considerations get in the way.

We don't have random assignment (because we're not assigning treatment to groups), but we also don't have a random sample. Mothers and infants were recruited from 4 hospitals, but their participation was voluntary (again, pesky ethics). So this isn't a random sample either.

It is possible that it is a represenative sample of the local population, if you trust the researcher assessment of the demographics of the region, and we don't try to generalize to groups other than white infants in western michigan. It's probably not something that would pass muster if researchers tried to generalize to all infants in the US, or infants worldwide. There are too many other cultural, racial, medical, and environmental factors.

Because this isn't an experiment, we can't make any causal conclusions. All we might be able to say is that there is an association between feeding method and intelligence.


---
## Example 6.3: Breastfeeding and Intelligence

The researchers followed up with the children at age 4, assessing their abilities using the McCarthy Scales of Children's Abilities. The GCI (General Cognitive Index) was recorded for each child, along with whether or not the child was breastfed.

What should the researchers use as their hypotheses, in words?

???

It's hard to give babies intelligence tests - they're nonverbal, squirmy, have no attention span... so the researchers waited until the kids were 4 and then assessed their intelligence and whether or not the child was breastfed.

What are the appropriate hypotheses in words?

---
## Example 6.3: Breastfeeding and Intelligence

The researchers followed up with the children at age 4, assessing their abilities using the McCarthy Scales of Children's Abilities. The GCI (General Cognitive Index) was recorded for each child, along with whether or not the child was breastfed.

What should the researchers use as their hypotheses, in words?

.red[Null: There is no underlying association between breastfeeding during infancy and GCI at age 4.]

.red[Alt: There is an association between breastfeeding during infancy and GCI at age 4.]

???

The null hypothesis is that there is no association between breastfeeding in infancy and score on the GCI at age 4.

The alternative hypothesis is that there is an association between the two variables.

---
## Example 6.3: Breastfeeding and Intelligence

The researchers followed up with the children at age 4, assessing their abilities using the McCarthy Scales of Children's Abilities. The GCI (General Cognitive Index) was recorded for each child, along with whether or not the child was breastfed.

What are the hypotheses in symbols?

???

On your own, write the hypotheses we just described in words using symbols

---
## Example 6.3: Breastfeeding and Intelligence

The researchers followed up with the children at age 4, assessing their abilities using the McCarthy Scales of Children's Abilities. The GCI (General Cognitive Index) was recorded for each child, along with whether or not the child was breastfed.

What are the hypotheses in symbols?

.red[
`$$\begin{align}H_0: \mu_{BF} - \mu_{Not}&amp;= 0\\H_A: \mu_{BF} - \mu_{Not} &amp;\neq 0\end{align}$$`
]

OR

.red[
`$$\begin{align}H_0: \mu_{BF} &amp;= \mu_{Not}\\H_A: \mu_{BF} &amp;\neq \mu_{Not}\end{align}$$`
]

???

We use `\(\mu\)` because the response is quantitative, and we denote the two groups as `\(\mu_{BF}\)` and `\(\mu_{Not}\)`. We can write the hypotheses in two ways that are mathematically the same: either the difference between the two population means is 0, or the two population means are equal to each other for the null.

The alternative is that they are not equal - this is equivalent to saying "there is an association"

---
## Example 6.3: Breastfeeding and Intelligence

Summary Stats:

Group | n | Sample mean | Sample SD
----- | - | ----------- | ---------
Breastfed | 237 | 105.30 | 14.50
Not Breastfed | 85 | 100.90 | 14.00

Simulated Data:
&lt;img src="chapter-6-two-means_files/figure-html/unnamed-chunk-14-1.png" width="80%" style="display: block; margin: auto;" /&gt;

???

I didn't have the full data for the study, but I've simulated data consistent with the statistics reported in the paper. You can see that the median GCI score is slightly higher in breastfed infants, and the entire boxplot is slightly shifted up... 

but you can also see that there are a lot more breastfed babies than formula fed babies

How would we compute a confidence interval for the difference in average intelligence of breastfed and formula fed infants?


---
## Example 6.3: Breastfeeding and Intelligence

CI Option 1: Theory-ish based Confidence Interval

- Statistic `\(\pm\)` 2 SD(Statistic)    
SD of difference in means from simulation

&lt;img src="chapter-6-two-means_files/figure-html/unnamed-chunk-15-1.png" width="80%" style="display: block; margin: auto;" /&gt;

3.961 `\(\pm\)` 2 (1.815) = (0.331, 3.650)

???

The first option, which I've called the "theory-ish" based confidence interval, is to use the simulation standard error of the average difference. This is the lazy method - you don't have to actually do the calculation of the standard error, you make the computer do it automatically. However, because it's simulated, you're assuming the null hypothesis is true.... which probably isn't a big deal if the two groups have roughly equal sizes and standard deviations, but might be a problem if there are differences in the variability between the two groups in addition to the means.

---
## Example 6.3: Breastfeeding and Intelligence

CI Option 2: Theory based Confidence Interval

- Statistic `\(\pm\)` 2 SD(Statistic)    
SD of difference in means from formula

`$$\begin{align}SD(\overline x_1 - \overline x_2) &amp;= \sqrt{\frac{s_1^2}{n_1} + \frac{s_2^2}{n_2}} \\&amp;= \sqrt{\frac{14.5^2}{237} + \frac{14.0^2}{85}} \\&amp;= \sqrt{0.887 + 2.306} \\&amp;= 1.787\end{align}$$`
3.961 `\(\pm\)` 2 (1.787) = (0.387, 3.594)

On a test, use Option 2 unless it explicitly says you may use the simulation standard error

???

The better option is to calculate the standard deviation of the difference in sample means using a formula. You'll notice that this formula looks pretty similar to the standard error formula used for differences in proportions - instead of p times 1-p, we have s^2, but we're still weighting each variance by the sample size in the group.

On a test, you should always calculate the standard error of the difference unless you're told that you can use the simulated value for the standard error.


---
## Theory Based Inference

A standardized statistic is thus

`$$t = \frac{\text{statistic} - \text{hypothesized value}}{SE(\text{statistic})} = \frac{\overline x_1 - \overline x_2 - 0}{\sqrt{\frac{s_1^2}{n_1} + \frac{s_2^2}{n_2}}}$$` 

***
### Validity Conditions

Either

- a symmetric distribution in both groups

OR

- at least 20 observations in each group and sample distributions that are not highly skewed

If the validity conditions hold, you can use the guideline that if `\(t &gt; 2\)`, then the p-value is probably `\(&lt; 0.05\)`.


???

We can use the standard error to get a standardized statistic in the usual way.

To use Theory based inference, we need one of two things: both groups have symmetric distributions, or there are at least 20 observations in each group and the sample distributions are not too skewed.

Basically, the sample mean for each group has to be normally distributed -- so each group has to have symmetry or 20 observations, and then you can combine them and assume the result is also normally distributed.

If the validity conditions hold, you can assess the standardized statistic using the cutoff of 2, and assume that corresponds to a p-value of less than 0.05.

---
## Factors Affecting the Width of a CI

- size of `\(n_1\)` and `\(n_2\)`
  - If `\(N = n_1 + n_2\)` is constant, the difference between `\(n_1\)` and `\(n_2\)`
    - the more balanced, the smaller the margin of error (all else equal)
  - Higher `\(N\)` = smaller margin of error

- variability of group 1 and/or group 2

- multiplier

???

Just as in Chapter 5, the width of an interval is affected by 3 things: 

The group sizes -- both the overall number of observations, and the difference between the two group sizes. 

- More data = smaller standard error = smaller margin of error = narrower width.
- Balanced group sizes will have smaller margin of error than unbalanced group sizes, if everything else stays the same.

The next factor that affects the width is the variability of the two groups

The last thing that affects the width of a CI is the multiplier. 

With that, we're done with Chapter 6! Congratulations for making it this far.
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
